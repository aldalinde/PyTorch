{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BpooDtBoo6lB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtHSc_QVBMA_"
   },
   "source": [
    "# RNN for sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_JF4K6RYBMBD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JvvUAdYIBMBD"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d_xuNQjJBMBD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UlZbG7EpBMBE"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7NeiDDgvBMBE"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"text/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SA2Z8jyHBMBE",
    "outputId": "543b4c37-95fc-4672-a62f-818a6a6c21ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9cLysL0bXv4",
    "outputId": "a10a258b-1f2b-4568-d40f-99c74ce0a3f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZkoCxMJfBMBF"
   },
   "outputs": [],
   "source": [
    "# test is without labels, so we'll split train to train and validation dataframes on label (label 1 is less than 10%)\n",
    "X_train, X_test = train_test_split(df_train,test_size=0.3, stratify=df_train[['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7w2cxIsVugbN",
    "outputId": "ff483dbd-00ad-4b84-a939-4fbbca148496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22373 9589 31962\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uDbsgmlrBMBG"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in puncts)\n",
    "    txt = txt.lower()\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if (word not in sw) & (word.isalnum())]\n",
    "    # exclude all except letters and numbers\n",
    "   \n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rSowDgnLBMBG"
   },
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"en\"))\n",
    "puncts = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fqjo_3o2BMBG",
    "outputId": "c429f7a3-be1b-4adf-f84e-af7f4988dfb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22373/22373 [00:06<00:00, 3665.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9589/9589 [00:02<00:00, 3813.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "\n",
    "X_train['tweet'] = X_train['tweet'].progress_apply(preprocess_text)\n",
    "X_test['tweet'] = X_test['tweet'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "v7G2jv7Ro6lC",
    "outputId": "f2bc56cb-690f-47a6-fa1b-bf713ecf6d54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6BITCFbHBMBH"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(X_train['tweet'])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lA_ieuIBMBH",
    "outputId": "d66d19fe-fa6c-4d35-bab7-3c0ced353aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['euro area industrial production data head noh danske bank blog silver gold forex',\n",
       "       'user yum yum moms attractions16 conferencing nomnom',\n",
       "       'user finallllly leaving work streaming user user soon get home',\n",
       "       ...,\n",
       "       'exhausted staying lemans24 adrenaline really pumping ahead finish europeangp f1 lm24',\n",
       "       'rosematter comes 14 minutes im taking science final instead getting lipstick',\n",
       "       'weekend planed son'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus_train = X_train['tweet'].values\n",
    "text_corpus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0FlNQ0fhBMBI"
   },
   "outputs": [],
   "source": [
    "text_corpus_test = X_test['tweet'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2XxVPWao6lE",
    "outputId": "f2d965e5-a5fd-437e-ddfd-b657979a889f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 31872\n",
      "num_words after: 11662\n"
     ]
    }
   ],
   "source": [
    "counts = Counter()\n",
    "for sequence in text_corpus_train:\n",
    "    counts.update(sequence.split())\n",
    "\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))\n",
    "    \n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q6ClV7nio6lE"
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels, w2index, used_length):\n",
    "        self._txts = txts\n",
    "        self._labels = labels\n",
    "        self._length = used_length\n",
    "        self._w2index = w2index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    @lru_cache(50000)\n",
    "    def encode_sentence(self, txt):\n",
    "        encoded = np.zeros(self._length, dtype=int)\n",
    "        enc1 = np.array([self._w2index.get(word, self._w2index[\"UNK\"]) for word in txt.split()])\n",
    "        length = min(self._length, len(enc1))\n",
    "        encoded[:length] = enc1[:length]\n",
    "        return encoded\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encode_sentence(self._txts[index])\n",
    "        return torch.from_numpy(encoded.astype(np.int32)), self._labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LWCcjZ4hBMBJ"
   },
   "outputs": [],
   "source": [
    "used_length = max([len(i.split()) for i in text_corpus_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dxSAuc_Co6lG"
   },
   "outputs": [],
   "source": [
    "y_train = X_train['label'].values\n",
    "y_test = X_test['label'].values\n",
    "\n",
    "train_dataset = TwitterDataset(text_corpus_train, y_train, vocab2index, used_length)\n",
    "test_dataset = TwitterDataset(text_corpus_test, y_test, vocab2index, used_length)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVSR1OwrwBBp",
    "outputId": "719ce9da-1538-49f0-f7e6-a420859fc7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dzlCNORAo6lJ"
   },
   "outputs": [],
   "source": [
    "class LSTMFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, ht = self.lstm(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = lstm_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        # print(out.shape)\n",
    "        return torch.sigmoid(out)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ry57kdwsLGWf"
   },
   "outputs": [],
   "source": [
    "lstm_init = LSTMFixedLen(len(vocab2index), 128, 20, use_last=False)\n",
    "optimizer = torch.optim.Adam(lstm_init.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qw1Mpj_Co6lJ",
    "outputId": "818ed7f7-21f8-4724-8b1a-6a79226d21cf"
   },
   "outputs": [],
   "source": [
    "lstm_init.train()\n",
    "th = 0.5\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    lstm_init.train()\n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0], data[1]\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_init(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        \n",
    "    # выводим статистику о процессе обучения\n",
    "    lstm_init.eval()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "            f'Loss: {loss:.3f}. ' \\\n",
    "            f'Acc: {running_right / running_items:.3f} \\n')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "   \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3emMctnR8NZ",
    "outputId": "f9bf7eac-f324-4f45-ee70-380b2b4d4160"
   },
   "outputs": [],
   "source": [
    "test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "for j, data in enumerate(test_loader):\n",
    "    test_labels = data[1]\n",
    "    test_outputs = lstm_init(data[0])\n",
    "        \n",
    "        # подсчет ошибки на тесте\n",
    "    test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "    test_running_total += len(data[1])\n",
    "    pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "    test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    " \n",
    "print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtq6UR4co6lK"
   },
   "outputs": [],
   "source": [
    "class GRUFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, )\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        gru_out, ht = self.gru(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = gru_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O63l7qtHTnVF"
   },
   "outputs": [],
   "source": [
    "gru_init = GRUFixedLen(len(vocab2index), 128, 20, use_last=False)\n",
    "optimizer = torch.optim.Adam(gru_init.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_5BDD5Go6lK",
    "outputId": "c644fe5f-95f1-4b56-baf7-657dd611be5d"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs): \n",
    "    gru_init.train() \n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0], data[1]\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = gru_init(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        \n",
    "    # выводим статистику о процессе обучения\n",
    "    gru_init.eval()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "          f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "          f'Loss: {loss:.3f}. ' \\\n",
    "          f'Acc: {running_right / running_items:.3f}', end='\\n ')\n",
    "\n",
    "    \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmvlkggxWNjI",
    "outputId": "45fa21d9-197c-48f5-b21d-b65316fd9e08"
   },
   "outputs": [],
   "source": [
    "test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "for j, data in enumerate(test_loader):\n",
    "    test_labels = data[1]\n",
    "    test_outputs = gru_init(data[0])\n",
    "        \n",
    "        # подсчет ошибки на тесте\n",
    "    test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "    test_running_total += len(data[1])\n",
    "    pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "    test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    " \n",
    "print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zO2cQWXSK5tQ"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24YgtqKQo6lL"
   },
   "outputs": [],
   "source": [
    "# Можно строить lstm с переменным размером входа:\n",
    "class LSTM_variable_input(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xceUSuICBMBM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
